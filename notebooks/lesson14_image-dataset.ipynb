{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 14 - Create an image dataset\n",
    "\n",
    "> In preparation of lesson 15 we create an image dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "In this lecture we will create an image dataset that we can then use in the next lecture to build an image classifier. To get labeled data we will download the images from Google image searches. \n",
    "\n",
    "You should learn how to create new dataset, look at examples and save the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "This lesson prepares for lesson 15 where we will create an image classifier. This content will be similar to the first lesson of the fastai course. If you have time we recommend watching the the lesson recording.\n",
    "* Practical Deep Learning for Coders - Lesson 1: Image classification by fastai [[video](https://youtu.be/XfoYk_Z5AkI)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "Create at least one image dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Before we can create an image classifier we need to create a dataset with training data. We could you one of the standard image datasets but in real life you usually need to be creative to get enough labeled data for your use-case. We will download images from Google search to download images corresponding to a certain category.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<img src='images/data-meme.jpg' width='400'>\n",
    "</div>\n",
    "\n",
    "\n",
    "At the end of this notebook you should have at least one dataset with images of different categories. The format of the dataset should be the following:\n",
    "\n",
    "```\n",
    "data \n",
    "│\n",
    "└───dog_vs_cat_dataset\n",
    "    │\n",
    "    └───cat\n",
    "    │   │   cat_img_1.png\n",
    "    │   │   cat_img_2.png\n",
    "    │   │   ...\n",
    "    │\n",
    "    └───dog\n",
    "        │   dog_img_1.png\n",
    "        │   dog_img_2.png\n",
    "        │   ...\n",
    "```\n",
    "\n",
    "This is the same structure we already encountered when we trained a text classifier with `ULMFiT` in the last lecture. Every class is contained in a folder that is named after the class. We built a helper class called `ImageDownloader` that we can use to set this up. This class also downloads Google image search results automatically into these folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "In order to get the images from Google search we need the `chromium-chromedriver`. If you run this notebook on binder `chromium-chromedriver` is already installed. If you want to install it on an other machine you need to install it manually. On a linux machine this can be done with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! apt-get update\n",
    "# ! apt-get install chromium-chromedriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information visit https://www.chromium.org/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install fastai library\n",
    "First we need to install the fastai library since we need some of its helper functions to download images and then also visualise the downloaded images.\n",
    "\n",
    "> Note: This step might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastai --no-cache-dir -qq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can import the `ImageDownloader` and the fastai helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_downloader import ImageDownloader\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "Now we need to define where we want to save the dataset and what it should be called. As usual, we save it in the `../data/` folder. In this example I want to create a memes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data/')\n",
    "dataset_name = 'memes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information I can create a new `ImageDownloader` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dl = ImageDownloader(data_path, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will also create a new folder in the `data_path` called `'meme'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/housing.csv'),\n",
       " PosixPath('../data/housing_addresses.csv'),\n",
       " PosixPath('../data/housing_processed.csv'),\n",
       " PosixPath('../data/.DS_Store'),\n",
       " PosixPath('../data/solution.csv'),\n",
       " PosixPath('../data/zero_submission.csv'),\n",
       " PosixPath('../data/test.csv'),\n",
       " PosixPath('../data/.gitkeep'),\n",
       " PosixPath('../data/autos.csv'),\n",
       " PosixPath('../data/imdb.csv'),\n",
       " PosixPath('../data/train.csv'),\n",
       " PosixPath('../data/.ipynb_checkpoints'),\n",
       " PosixPath('../data/median_submission.csv'),\n",
       " PosixPath('../data/word2vec-google-news-300.pkl'),\n",
       " PosixPath('../data/fine_tuned.pth'),\n",
       " PosixPath('../data/sample_submission.csv'),\n",
       " PosixPath('../data/churn.csv'),\n",
       " PosixPath('../data/housing_gmaps_data_raw.csv')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new class\n",
    "We are now ready to create our first class in this dataset. We want to create two classes: one containing dank memes and another class with lame memes. Therefore we call the first class `'dank_meme'`. This will also be the name of the folder in the dataset folder. It is usually a good idea to avoid whitespaces when naming folders and files. You can replace them with underscores or dashes.\n",
    "\n",
    "The second piece of information we need is the search query. This is what you would enter on the Google search website. In this case we want to search for `'dank memes'`.\n",
    "\n",
    "> Note: Since a lot of information about a meme is stored in text written on top of the image this particular example could be very hard for image classifiers. Ideally, pick an example where all the necessary information for the classification is stored in the image itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'dank_meme'\n",
    "search_query = 'dank meme'\n",
    "\n",
    "img_dl.add_images_to_class(class_name, search_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the search query this should yield somewhere between 100-700 images that are stored in the class folder. Maybe you want to download images from several search queries into the same class folder. You can do that with the image downloader. Simply create another query and pass it with the same class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = 'great meme'\n",
    "\n",
    "img_dl.add_images_to_class(class_name, search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = 'funny meme'\n",
    "\n",
    "img_dl.add_images_to_class(class_name, search_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be enough images for that class to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create another class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to create the second class in our dataset with lame memes. To do so we can run the same function but with a different `class_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'lame_meme'\n",
    "search_query = 'lame meme'\n",
    "\n",
    "img_dl.add_images_to_class(class_name, search_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create as many classes as you want withing one dataset. For the purpose of next weeks lecture we suggest creating at least one dataset with 2-20 classes. Of course you can also create more than one dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete dataset\n",
    "It can happen that you want to start from scratch. Unfortunately, deleting folders that contain files is not possible from within JupyterLab. You can use the following command to delete a folder with all its content.\n",
    "\n",
    "> Warning: This command is not reversible and deletes all the contents of the target folder recursively. Make sure you don't run it on the wrong folder on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ../data/my_dataset_name/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete class\n",
    "If you only want to delete a certain class in your dataset you can do this with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ../data/my_dataset_name/my_class/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at some examples\n",
    "Finally we want to look at some examples. This might look familiar from the data loading functions in the last lecture and is indeed also part of the fastai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_folder(data_path/dataset_name, size=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we loaded the data we can plot a random selection of images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(8, 8)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "Finally, we need to download the dataset, since storage on Binder is not persistent. Downloading each image individually is note really practical, therefore we compress the dataset folder which we can then download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -zcf {data_path/dataset_name}.tar.gz {data_path/dataset_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clicking on the folder icon on the top left of the JupyterLab user interface you should be able to navigate to the `'../data/'` folder and then right click on the compressed file (with the file ending `.tar.gz` and download it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
